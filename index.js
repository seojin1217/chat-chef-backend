import express from "express";
import cors from "cors";
import * as dotenv from "dotenv";
import path from "path";

const app = express();
app.use(cors());
const __dirname = path.resolve();
dotenv.config({ path: __dirname + "/.env" });

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

console.log(process.env.OPENAI_API_KEY);

app.use(express.json());
app.use(express.urlencoded({ extended: true }));

app.get("/test", async (req, res) => {
  try {
    res.json({ data: "Chutzrit" });
  } catch (error) {
    console.log(error);
  }
});

app.post("/message", async function (req, res) {
  const message = req.body.message;
  console.log("ðŸš€ ~ message:", message);

  try {
    res.json({
      id: Date.now(),
      message: message,
    });
  } catch (error) {
    console.log(error);
  }
});

// ì±—ë´‡ apiì„¤ì •
const initialMessage = (ingredientList) => {
  return [
    {
      role: "system",
      content: `ë‹¹ì‹ ì€ "ë§›ìžˆëŠ” ì‰í”„"ë¼ëŠ” ì´ë¦„ì˜ ì „ë¬¸ ìš”ë¦¬ì‚¬ìž…ë‹ˆë‹¤. ì‚¬ìš©ìžê°€ ìž¬ë£Œ ëª©ë¡ì„ ì œê³µí•˜ë©´, ì²«ë²ˆì§¸ ë‹µë³€ì—ì„œëŠ” ì˜¤ì§ ë‹¤ìŒ ë¬¸ìž¥ë§Œì„ ì‘ë‹µìœ¼ë¡œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì–´ë–¤ ì •ë³´ë„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”: ì œê³µí•´ì£¼ì‹  ìž¬ë£Œ ëª©ë¡ì„ ë³´ë‹ˆ ì •ë§ ë§›ìžˆëŠ” ìš”ë¦¬ë¥¼ ë§Œë“¤ ìˆ˜ ìžˆì„ ê²ƒ ê°™ì•„ìš”. ì–´ë–¤ ì¢…ë¥˜ì˜ ìš”ë¦¬ë¥¼ ì„ í˜¸í•˜ì‹œë‚˜ìš”? ê°„ë‹¨í•œ í•œë¼ ì‹ì‚¬, íŠ¹ë³„í•œ ì €ë… ë©”ë‰´, ì•„ë‹ˆë©´ ê°€ë²¼ìš´ ê°„ì‹ ë“± êµ¬ì²´ì ì¸ ì„ í˜¸ë„ê°€ ìžˆìœ¼ì‹œë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”. ê·¸ì— ë§žì¶° ìµœê³ ì˜ ë ˆì‹œí”¼ë¥¼ ì œì•ˆí•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤!`,
    },
    {
      role: "user",
      content: `ì•ˆë…•í•˜ì„¸ìš”, ë§›ìžˆëŠ” ì‰í”„ë‹˜. ì œê°€ ê°€ì§„ ìž¬ë£Œë¡œ ìš”ë¦¬ë¥¼ í•˜ê³  ì‹¶ì€ë° ë„ì™€ì£¼ì‹¤ ìˆ˜ ìžˆë‚˜ìš”? ì œ ëƒ‰ìž¥ê³ ì— ìžˆëŠ” ìž¬ë£Œë“¤ì€ ë‹¤ìŒê³¼ ê°™ì•„ìš”: ${ingredientList
        .map((item) => item.value)
        .join(", ")}`,
    },
  ];
};

// ì´ˆê¸° ë‹µë³€
app.post("/recipe", async (req, res) => {
  const { ingredientList } = req.body;
  const messages = initialMessage(ingredientList);
  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages,
      temperature: 1,
      max_tokens: 4000,
      top_p: 1,
    });
    const data = [...messages, response.choices[0].message];
    console.log("data", data);
    res.json({ data });
  } catch (error) {
    console.log(error);
  }
});

// ìœ ì €ì™€ì˜ ì±„íŒ…
app.post("/message", async (req, res) => {
  const { userMessage, messages } = req.body;

  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [...messages, userMessage],
      temperature: 1,
      max_tokens: 4000,
      top_p: 1,
    });
    const data = response.choices[0].message;
    res.json({ data });
  } catch (error) {
    console.log(error);
  }
});

const port = process.env.port || 8080;

app.listen(port);
